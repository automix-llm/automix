# automix


## What is AutoMix?

The idea behind AutoMix is simple: 

1. Send a query to small language model (SLM), gets a noisy label on its correctness using few-shot self-verification done with the same model (SLM).
2. Use a meta-verifier to "double check" verifier's output.Depending on the final output, we can either trust the SLM's output or not. If we decide not to, we send the query to a large language model (LLM).


## Data

- We experiment with 5 datasets: CNLI, CoQA, NarrativeQA, QASPER, and Quality. A single file with input.


## Notebooks

### Running inference

[**Step1 Run inference to solve tasks**](https://github.com/automix-llm/automix/blob/main/colabs/Step1_SolveQueries.ipynb) - Brief explanation here.
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/automix-llm/automix/blob/main/colabs/Step1_SolveQueries.ipynb)

### Few-shot self-verification

- [**Step2 Self Verify**](https://github.com/automix-llm/automix/blob/main/colabs/Step2_SelfVerify.ipynb) - A sentence about this notebook’s purpose.
   [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/automix-llm/automix/blob/main/colabs/Step2_SelfVerify.ipynb)



### Meta-verification




## What are we releasing


```
id: A unique identifier for each question and answer pair.
pid: An additional identifier potentially mapping to specific instances or model variants.
base_ctx: The context.
question: Input question or query.
output: Ground truth.
dataset: .
llama13b_pred_ans: The answer generated by the llama13b model.
llama70b_pred_ans: The answer generated by the llama70b model.
llama13b_ver: Verification outputs of the llama13b model’s answers.
```

- Note: The dataset are sourced from [scrolls](https://www.scrolls-benchmark.com/). Please cite scrolls and the appropriate sources if we use these datasets. We are making them available in a sinlge jsonl file for ease of use and reproducibility.

### Stats

```txt
dataset       split
cnli          train    7191
              val      1037
coqa          train    3941
              val      3908
narrative_qa  train    9946
              val      5826
qasper        train    2556
              val      1715
quality       train    2515
              val      2085
Name: split, dtype: int64
```

- Outputs from LLAMA13B and LLAMA70B


### Sample row


## Metrics


## Starting OpenAI server for LLAMA2




